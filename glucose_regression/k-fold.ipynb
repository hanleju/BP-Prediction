{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>antihypertensives</th>\n",
       "      <th>dbp</th>\n",
       "      <th>fasting</th>\n",
       "      <th>glucose</th>\n",
       "      <th>height</th>\n",
       "      <th>pulse</th>\n",
       "      <th>sbp</th>\n",
       "      <th>temp</th>\n",
       "      <th>weight</th>\n",
       "      <th>pat_sex</th>\n",
       "      <th>pat_birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>169.8</td>\n",
       "      <td>75.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>37.1</td>\n",
       "      <td>65.7</td>\n",
       "      <td>F</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>171.1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>65.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>169.6</td>\n",
       "      <td>79.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>37.1</td>\n",
       "      <td>64.1</td>\n",
       "      <td>F</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>148.7</td>\n",
       "      <td>58.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>49.4</td>\n",
       "      <td>F</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>151.3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>36.2</td>\n",
       "      <td>48.9</td>\n",
       "      <td>F</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  antihypertensives   dbp  fasting  glucose  height  pulse    sbp  temp  \\\n",
       "0   0                0.0  79.0      1.0    100.0   169.8   75.0  123.0  37.1   \n",
       "1   0                0.0  70.0      1.0    106.0   171.1   69.0  109.0  36.4   \n",
       "2   0                0.0  70.0      1.0    106.0   169.6   79.0  109.0  37.1   \n",
       "3   1                0.0  82.0      1.0    100.0   148.7   58.0  140.0  35.9   \n",
       "4   1                1.0  73.0      1.0    100.0   151.3   59.0  108.0  36.2   \n",
       "\n",
       "   weight pat_sex  pat_birth  \n",
       "0    65.7       F       1971  \n",
       "1    65.0       F       1971  \n",
       "2    64.1       F       1971  \n",
       "3    49.4       F       1959  \n",
       "4    48.9       F       1959  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "\n",
    "file_path = 'merged_2.csv'\n",
    "\n",
    "df = pd.read_csv(file_path, encoding='euc-kr')\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) for each fold: ['393.36', '1025.37', '187.68', '446.93', '751.04']\n",
      "Average MSE: 560.88\n"
     ]
    }
   ],
   "source": [
    "# df = df[df['glucose'] <= 140]\n",
    "\n",
    "features = df.drop(['glucose'], axis=1)\n",
    "targets = df['glucose']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "features['pat_sex'] = label_encoder.fit_transform(features['pat_sex'])\n",
    "\n",
    "# Remove 'id' column\n",
    "features = features.drop(['id'], axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the training data into train and test sets for optimization\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "mse_scores = []\n",
    "fold_indices = []\n",
    "\n",
    "for fold_index, (train_index, test_index) in enumerate(kf.split(features)):\n",
    "    X_train_fold, X_test_fold = features[train_index], features[test_index]\n",
    "    y_train_fold, y_test_fold = targets.values[train_index], targets.values[test_index]\n",
    "    \n",
    "    model = cb.CatBoostRegressor(n_estimators=10000, learning_rate=0.005, max_depth=10, random_state=42, verbose=0)\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    y_pred_fold = model.predict(X_test_fold)\n",
    "    mse = mean_squared_error(y_test_fold, y_pred_fold)\n",
    "    \n",
    "    mse_scores.append(mse)\n",
    "    fold_indices.append((train_index, test_index))\n",
    "\n",
    "print(\"Mean Squared Error (MSE) for each fold:\", [f\"{mse:.2f}\" for mse in mse_scores])\n",
    "print(\"Average MSE:\", f\"{np.mean(mse_scores):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-10 14:19:10,570] A new study created in memory with name: no-name-41f6fdfc-b35e-4524-b351-1d9750a89b9b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for fold with median MSE, fold index: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-10 14:19:56,971] Trial 0 finished with value: 423.97720869483345 and parameters: {'iterations': 20000, 'learning_rate': 0.0036160624950885662, 'depth': 9}. Best is trial 0 with value: 423.97720869483345.\n",
      "[I 2024-07-10 14:20:08,551] Trial 1 finished with value: 418.17155648517013 and parameters: {'iterations': 5059, 'learning_rate': 0.007842259171626773, 'depth': 9}. Best is trial 1 with value: 418.17155648517013.\n",
      "[I 2024-07-10 14:20:25,473] Trial 2 finished with value: 390.54725056332154 and parameters: {'iterations': 19481, 'learning_rate': 0.00399641719075067, 'depth': 7}. Best is trial 2 with value: 390.54725056332154.\n",
      "[I 2024-07-10 14:20:43,155] Trial 3 finished with value: 416.0410166114171 and parameters: {'iterations': 12713, 'learning_rate': 0.004074381834069926, 'depth': 8}. Best is trial 2 with value: 390.54725056332154.\n",
      "[I 2024-07-10 14:21:29,674] Trial 4 finished with value: 441.8999019838932 and parameters: {'iterations': 9158, 'learning_rate': 0.007333940062215498, 'depth': 10}. Best is trial 2 with value: 390.54725056332154.\n",
      "[I 2024-07-10 14:21:36,606] Trial 5 finished with value: 368.778586682727 and parameters: {'iterations': 12156, 'learning_rate': 0.0034955602005936077, 'depth': 6}. Best is trial 5 with value: 368.778586682727.\n",
      "[I 2024-07-10 14:21:49,063] Trial 6 finished with value: 408.9307731485124 and parameters: {'iterations': 9002, 'learning_rate': 0.0029408313257747783, 'depth': 8}. Best is trial 5 with value: 368.778586682727.\n",
      "[I 2024-07-10 14:21:53,643] Trial 7 finished with value: 407.5382964138169 and parameters: {'iterations': 5324, 'learning_rate': 0.002703847574170897, 'depth': 7}. Best is trial 5 with value: 368.778586682727.\n",
      "[I 2024-07-10 14:22:18,707] Trial 8 finished with value: 394.6621924233475 and parameters: {'iterations': 17897, 'learning_rate': 0.00838667571180895, 'depth': 8}. Best is trial 5 with value: 368.778586682727.\n",
      "[I 2024-07-10 14:22:35,814] Trial 9 finished with value: 382.2061344127507 and parameters: {'iterations': 19852, 'learning_rate': 0.0011478471555123302, 'depth': 7}. Best is trial 5 with value: 368.778586682727.\n",
      "[I 2024-07-10 14:22:44,145] Trial 10 finished with value: 373.6199707484428 and parameters: {'iterations': 14791, 'learning_rate': 0.0015431304447959125, 'depth': 6}. Best is trial 5 with value: 368.778586682727.\n",
      "[I 2024-07-10 14:22:52,359] Trial 11 finished with value: 369.41293747256907 and parameters: {'iterations': 14655, 'learning_rate': 0.0017029829341388325, 'depth': 6}. Best is trial 5 with value: 368.778586682727.\n",
      "[I 2024-07-10 14:23:00,928] Trial 12 finished with value: 376.7137518429359 and parameters: {'iterations': 15177, 'learning_rate': 0.001985387072415294, 'depth': 6}. Best is trial 5 with value: 368.778586682727.\n",
      "[I 2024-07-10 14:23:06,947] Trial 13 finished with value: 391.7128878163592 and parameters: {'iterations': 10755, 'learning_rate': 0.00187384538388138, 'depth': 6}. Best is trial 5 with value: 368.778586682727.\n",
      "[I 2024-07-10 14:23:15,210] Trial 14 finished with value: 374.39462993750595 and parameters: {'iterations': 14497, 'learning_rate': 0.005562021188804063, 'depth': 6}. Best is trial 5 with value: 368.778586682727.\n",
      "[I 2024-07-10 14:23:26,009] Trial 15 finished with value: 421.629838521491 and parameters: {'iterations': 12557, 'learning_rate': 0.0010533348937844772, 'depth': 7}. Best is trial 5 with value: 368.778586682727.\n",
      "[I 2024-07-10 14:23:35,323] Trial 16 finished with value: 373.59112916024225 and parameters: {'iterations': 16094, 'learning_rate': 0.002343730248186722, 'depth': 6}. Best is trial 5 with value: 368.778586682727.\n",
      "[I 2024-07-10 14:23:44,454] Trial 17 finished with value: 414.0837381300616 and parameters: {'iterations': 10730, 'learning_rate': 0.0014730132415943038, 'depth': 7}. Best is trial 5 with value: 368.778586682727.\n",
      "[I 2024-07-10 14:24:25,428] Trial 18 finished with value: 424.1727368936921 and parameters: {'iterations': 17567, 'learning_rate': 0.00514118148321142, 'depth': 9}. Best is trial 5 with value: 368.778586682727.\n",
      "[I 2024-07-10 14:24:32,995] Trial 19 finished with value: 379.71653444352086 and parameters: {'iterations': 13326, 'learning_rate': 0.002255606434498051, 'depth': 6}. Best is trial 5 with value: 368.778586682727.\n",
      "[I 2024-07-10 14:25:27,249] Trial 20 finished with value: 455.3566598467453 and parameters: {'iterations': 10642, 'learning_rate': 0.001517749674188723, 'depth': 10}. Best is trial 5 with value: 368.778586682727.\n",
      "[I 2024-07-10 14:25:36,566] Trial 21 finished with value: 361.6867603240592 and parameters: {'iterations': 16267, 'learning_rate': 0.0024982026124189057, 'depth': 6}. Best is trial 21 with value: 361.6867603240592.\n",
      "[I 2024-07-10 14:25:46,302] Trial 22 finished with value: 371.3752653538475 and parameters: {'iterations': 16936, 'learning_rate': 0.00328680338688011, 'depth': 6}. Best is trial 21 with value: 361.6867603240592.\n",
      "[I 2024-07-10 14:25:58,494] Trial 23 finished with value: 380.1184245873441 and parameters: {'iterations': 13915, 'learning_rate': 0.0025731461330529767, 'depth': 7}. Best is trial 21 with value: 361.6867603240592.\n",
      "[I 2024-07-10 14:26:07,632] Trial 24 finished with value: 376.4309393718731 and parameters: {'iterations': 15726, 'learning_rate': 0.001793389227044848, 'depth': 6}. Best is trial 21 with value: 361.6867603240592.\n",
      "[I 2024-07-10 14:26:17,731] Trial 25 finished with value: 388.7742034473215 and parameters: {'iterations': 11585, 'learning_rate': 0.005176588524965157, 'depth': 7}. Best is trial 21 with value: 361.6867603240592.\n",
      "[I 2024-07-10 14:26:27,225] Trial 26 finished with value: 378.37002920779395 and parameters: {'iterations': 16623, 'learning_rate': 0.0013654098078309516, 'depth': 6}. Best is trial 21 with value: 361.6867603240592.\n",
      "[I 2024-07-10 14:26:43,822] Trial 27 finished with value: 393.488672775121 and parameters: {'iterations': 18570, 'learning_rate': 0.002276071050364722, 'depth': 7}. Best is trial 21 with value: 361.6867603240592.\n",
      "[I 2024-07-10 14:26:48,444] Trial 28 finished with value: 379.46349879426606 and parameters: {'iterations': 8239, 'learning_rate': 0.003314149446222937, 'depth': 6}. Best is trial 21 with value: 361.6867603240592.\n",
      "[I 2024-07-10 14:27:05,092] Trial 29 finished with value: 411.6717040888377 and parameters: {'iterations': 11884, 'learning_rate': 0.003893306549049491, 'depth': 8}. Best is trial 21 with value: 361.6867603240592.\n",
      "[I 2024-07-10 14:27:13,066] Trial 30 finished with value: 379.5230797564277 and parameters: {'iterations': 13772, 'learning_rate': 0.004469873738331525, 'depth': 6}. Best is trial 21 with value: 361.6867603240592.\n",
      "[I 2024-07-10 14:27:22,619] Trial 31 finished with value: 366.1773297700499 and parameters: {'iterations': 16792, 'learning_rate': 0.003224586978678803, 'depth': 6}. Best is trial 21 with value: 361.6867603240592.\n",
      "[I 2024-07-10 14:27:31,807] Trial 32 finished with value: 371.09281875011993 and parameters: {'iterations': 15894, 'learning_rate': 0.0030210771707708754, 'depth': 6}. Best is trial 21 with value: 361.6867603240592.\n",
      "[I 2024-07-10 14:27:47,469] Trial 33 finished with value: 401.8766006260952 and parameters: {'iterations': 17921, 'learning_rate': 0.0019383778611173736, 'depth': 7}. Best is trial 21 with value: 361.6867603240592.\n",
      "[I 2024-07-10 14:27:56,073] Trial 34 finished with value: 359.8194003868226 and parameters: {'iterations': 15021, 'learning_rate': 0.0035185342777611043, 'depth': 6}. Best is trial 34 with value: 359.8194003868226.\n",
      "[I 2024-07-10 14:28:35,142] Trial 35 finished with value: 430.409997249992 and parameters: {'iterations': 16709, 'learning_rate': 0.0035850885164390198, 'depth': 9}. Best is trial 34 with value: 359.8194003868226.\n",
      "[I 2024-07-10 14:28:52,157] Trial 36 finished with value: 383.23322361507934 and parameters: {'iterations': 18929, 'learning_rate': 0.006242593908084991, 'depth': 7}. Best is trial 34 with value: 359.8194003868226.\n",
      "[I 2024-07-10 14:29:00,308] Trial 37 finished with value: 390.56277104980103 and parameters: {'iterations': 13023, 'learning_rate': 0.00428366888831514, 'depth': 6}. Best is trial 34 with value: 359.8194003868226.\n",
      "[I 2024-07-10 14:29:36,840] Trial 38 finished with value: 424.33160249224727 and parameters: {'iterations': 15503, 'learning_rate': 0.00264755053802555, 'depth': 9}. Best is trial 34 with value: 359.8194003868226.\n",
      "[I 2024-07-10 14:29:47,350] Trial 39 finished with value: 368.8531581369227 and parameters: {'iterations': 17573, 'learning_rate': 0.0035773987024063456, 'depth': 6}. Best is trial 34 with value: 359.8194003868226.\n",
      "[I 2024-07-10 14:30:07,057] Trial 40 finished with value: 415.47085707947616 and parameters: {'iterations': 14057, 'learning_rate': 0.002906486693818974, 'depth': 8}. Best is trial 34 with value: 359.8194003868226.\n",
      "[I 2024-07-10 14:30:16,888] Trial 41 finished with value: 370.8323707078305 and parameters: {'iterations': 17218, 'learning_rate': 0.0036200407772261516, 'depth': 6}. Best is trial 34 with value: 359.8194003868226.\n",
      "[I 2024-07-10 14:30:27,651] Trial 42 finished with value: 378.52168841739524 and parameters: {'iterations': 18603, 'learning_rate': 0.0037259450840648736, 'depth': 6}. Best is trial 34 with value: 359.8194003868226.\n",
      "[I 2024-07-10 14:30:36,825] Trial 43 finished with value: 367.5365402984156 and parameters: {'iterations': 16249, 'learning_rate': 0.009644195918451677, 'depth': 6}. Best is trial 34 with value: 359.8194003868226.\n",
      "[I 2024-07-10 14:30:51,093] Trial 44 finished with value: 401.4335790991768 and parameters: {'iterations': 16195, 'learning_rate': 0.009160325922304804, 'depth': 7}. Best is trial 34 with value: 359.8194003868226.\n",
      "[I 2024-07-10 14:30:59,731] Trial 45 finished with value: 374.57818365580016 and parameters: {'iterations': 14925, 'learning_rate': 0.00686177069324188, 'depth': 6}. Best is trial 34 with value: 359.8194003868226.\n",
      "[I 2024-07-10 14:31:06,470] Trial 46 finished with value: 366.04007094732964 and parameters: {'iterations': 11732, 'learning_rate': 0.009728686572970286, 'depth': 6}. Best is trial 34 with value: 359.8194003868226.\n",
      "[I 2024-07-10 14:31:15,092] Trial 47 finished with value: 357.3446059407125 and parameters: {'iterations': 15301, 'learning_rate': 0.009602767848120607, 'depth': 6}. Best is trial 47 with value: 357.3446059407125.\n",
      "[I 2024-07-10 14:31:19,912] Trial 48 finished with value: 404.82791098220883 and parameters: {'iterations': 5587, 'learning_rate': 0.006945321420634343, 'depth': 7}. Best is trial 47 with value: 357.3446059407125.\n",
      "[I 2024-07-10 14:31:28,569] Trial 49 finished with value: 370.0217997633954 and parameters: {'iterations': 15388, 'learning_rate': 0.008224883597749744, 'depth': 6}. Best is trial 47 with value: 357.3446059407125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'iterations': 15301, 'learning_rate': 0.009602767848120607, 'depth': 6}\n",
      "Optimized MSE: 357.34\n"
     ]
    }
   ],
   "source": [
    "# Find the median MSE fold\n",
    "median_mse_index = np.argsort(mse_scores)[len(mse_scores) // 2]\n",
    "selected_fold_train_index, selected_fold_test_index = fold_indices[median_mse_index]\n",
    "\n",
    "print(f\"Optimizing for fold with median MSE, fold index: {median_mse_index}\")\n",
    "\n",
    "X_train_opt = features[selected_fold_train_index]\n",
    "y_train_opt = targets.values[selected_fold_train_index]\n",
    "X_test_opt = features[selected_fold_test_index]\n",
    "y_test_opt = targets.values[selected_fold_test_index]\n",
    "\n",
    "# Objective function for Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'iterations': trial.suggest_int('iterations', 5000, 20000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.01, log=True),\n",
    "        'depth': trial.suggest_int('depth', 6, 10),\n",
    "        'random_state': 42,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    \n",
    "    model = cb.CatBoostRegressor(**param)\n",
    "    model.fit(X_train_opt, y_train_opt)\n",
    "    y_pred = model.predict(X_test_opt)\n",
    "    mse = mean_squared_error(y_test_opt, y_pred)\n",
    "    return mse\n",
    "\n",
    "# Perform hyperparameter tuning using Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Optimized MSE:\", f\"{study.best_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Optimized MSE: 357.34\n",
      "Predictions saved to glucose_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Train the best model\n",
    "best_params = study.best_params\n",
    "best_model = cb.CatBoostRegressor(**best_params, random_state=42, verbose=0)\n",
    "best_model.fit(X_train_opt, y_train_opt)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred_opt = best_model.predict(X_test_opt)\n",
    "mse_opt = mean_squared_error(y_test_opt, y_pred_opt)\n",
    "print(\"Final Optimized MSE:\", f\"{mse_opt:.2f}\")\n",
    "\n",
    "# Load the new data\n",
    "merged_test_2 = pd.read_csv('merged_test_2.csv')\n",
    "\n",
    "# Preprocess the new data\n",
    "merged_test_2['pat_sex'] = label_encoder.transform(merged_test_2['pat_sex'])\n",
    "merged_test_2 = merged_test_2.drop(['id'], axis=1)\n",
    "merged_test_2 = scaler.transform(merged_test_2)\n",
    "\n",
    "# Predict the glucose values\n",
    "glucose_predictions = best_model.predict(merged_test_2)\n",
    "\n",
    "# Save the predictions to a new CSV file\n",
    "predictions_df = pd.DataFrame(glucose_predictions, columns=['glucose'])\n",
    "predictions_df.to_csv('glucose_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to glucose_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
